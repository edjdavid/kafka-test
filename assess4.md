1. Test the difference between data storage types (json, avro, csv, compressed json/csv). The current application produces very small data so the difference between using these data types might not be apparent but on large volumes it would have an effect on data transfer, storage, and loading. ksql-datagen has support for using different data formats as well as kafka-connect.
1. Use an analytical SQL layer on top of an object store (Presto, Snowflake). The application connects directly to the object store but is using Python for data manipulation/aggragation which might not be comfortable for a lot of people. Can also transfer the data from object store to a data warehouse as it would be faster and efficient than processing the raw files everytime.
1. Test setting up high availabity for the data producer and consumer. Also, high traffic and multi-user for the dashboard as it might work correctly when subjected to small loads but might fail, or cause unexpected issues, when using higher loads. 